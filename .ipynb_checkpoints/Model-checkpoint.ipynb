{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8816b6-2779-4f75-9326-12545360bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import exp, where, erf, tensor, log, argwhere, ones_like, ones, heaviside, sign\n",
    "from torch import pow as POW\n",
    "from numpy import pi, e\n",
    "from scipy.special import expi\n",
    "from numpy import log as nplog \n",
    "from torch import max as Max\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf as sp_erf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369026d3-1a81-4de0-9352-42df07a776f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "%run actFunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9ce9c-0228-4133-957a-2e0449ef6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class actModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, hid_dim, out_dim, n_layer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_proj = nn.Linear(in_dim, hid_dim, bias=True)\n",
    "        \n",
    "        #Model layers \n",
    "        self.layers = nn.ModuleList([self.ResidualBlock(hid_dim) for _ in range(n_layer)])\n",
    "\n",
    "        #normalization layer \n",
    "        self.norm = nn.RMSNorm(hid_dim) \n",
    "\n",
    "        #output projection \n",
    "        self.out_proj = nn.Linear(hid_dim, out_dim, bias=True)\n",
    "\n",
    "        #output activation function \n",
    "        self.activation =  nn.Softmax(dim=1)\n",
    "        \n",
    "        #Loss function \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    #Forward function \n",
    "    def forward(self, x):\n",
    "\n",
    "        #Flatten image \n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        #encoder block \n",
    "        x = self.in_proj(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "\n",
    "        #Do forward pass for residual layers \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        #decoder block\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        x = self.out_proj(x)\n",
    "\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self.forward(images)                  # Generate predictions\n",
    "        loss = self.criterion(out, labels) # Calculate loss\n",
    "        return loss\n",
    "\n",
    "    def accuracy(self, outputs, labels):\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self.forward(images)                 # Generate predictions\n",
    "        loss = self.criterion(out, labels)         # Calculate loss\n",
    "        acc = self.accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}] val_loss: {:.4f}, val_acc: {:.4f}, time: {:.4f} s\".format(epoch, result['val_loss'], result['val_acc'], result['epoch_time']))\n",
    "\n",
    "    #residual block \n",
    "    class ResidualBlock(nn.Module):\n",
    "            \n",
    "        def __init__(self, hid_dim):\n",
    "            super().__init__()\n",
    "\n",
    "            #linear weight layer \n",
    "            self.proj = nn.Linear(hid_dim, hid_dim, bias=True)\n",
    "            #normalization layer \n",
    "            self.norm = nn.RMSNorm(hid_dim)\n",
    "            \n",
    "            #choose activation layer\n",
    "            #self.activation = nn.LeakyReLU(0.01)\n",
    "            #self.activation = supeRelu5()\n",
    "            #self.activation = supeLeakRelu1()\n",
    "            #self.activation = supeRelu.apply\n",
    "            #self.activation = softplusplus.apply\n",
    "            #self.activation = nn.Softplus()\n",
    "            #self.activation = nn.SELU()\n",
    "            #self.activation = nn.Mish()\n",
    "            self.activation = squarePlus1()\n",
    "            #self.activation = modifiedElliot.apply\n",
    "\n",
    "        #forward pass \n",
    "        def forward(self, x):\n",
    "\n",
    "            #return self.activation(self.norm(self.proj(x))) \n",
    "\n",
    "            return self.activation(self.proj(self.norm(x))) + x\n",
    "\n",
    "            #return self.activation(self.proj(x)) + x \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4590139-ed62-410b-89aa-7e67336ce71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e1e046-8c94-43f4-af81-d7694c1a8760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
