{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 images\n",
      "Processed 1001 images\n",
      "Processed 2001 images\n",
      "Processed 3001 images\n",
      "Processed 4001 images\n",
      "Processed 5001 images\n",
      "Processed 6001 images\n",
      "Processed 7001 images\n",
      "Processed 8001 images\n",
      "Processed 9001 images\n",
      "Processed 10001 images\n",
      "Processed 11001 images\n",
      "Processed 12001 images\n",
      "Processed 13001 images\n",
      "Processed 14001 images\n",
      "Processed 15001 images\n",
      "Processed 16001 images\n",
      "Processed 17001 images\n",
      "Processed 18001 images\n",
      "Processed 19001 images\n",
      "Processed 20001 images\n",
      "Processed 21001 images\n",
      "Processed 22001 images\n",
      "Processed 23001 images\n",
      "Processed 24001 images\n",
      "Processed 25001 images\n",
      "Processed 26001 images\n",
      "Processed 27001 images\n",
      "Processed 28001 images\n",
      "Processed 29001 images\n",
      "Processed 30001 images\n",
      "Processed 31001 images\n",
      "Processed 32001 images\n",
      "Processed 33001 images\n",
      "Processed 34001 images\n",
      "Processed 35001 images\n",
      "Processed 36001 images\n",
      "Processed 37001 images\n",
      "Processed 38001 images\n",
      "Processed 39001 images\n",
      "Processed 40001 images\n",
      "Processed 41001 images\n",
      "Processed 42001 images\n",
      "Processed 43001 images\n",
      "Processed 44001 images\n",
      "Processed 45001 images\n",
      "Processed 46001 images\n",
      "Processed 47001 images\n",
      "Processed 48001 images\n",
      "Processed 49001 images\n",
      "Processed 50001 images\n",
      "Processed 51001 images\n",
      "Processed 52001 images\n",
      "Processed 53001 images\n",
      "Processed 54001 images\n",
      "Processed 55001 images\n",
      "Processed 56001 images\n",
      "Processed 57001 images\n",
      "Processed 58001 images\n",
      "Processed 59001 images\n",
      "Mixed noisy dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define the noise functions\n",
    "def noisy(noise_typ, image):\n",
    "    if noise_typ == \"gauss\":\n",
    "        row, col, ch = image.shape\n",
    "        mean = 0\n",
    "        var = 0.01\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "        gauss = gauss.reshape(row, col, ch)\n",
    "        noisy = image + gauss\n",
    "        return np.clip(noisy, 0, 1)  # Clip values to ensure they stay within [0, 1]\n",
    "    elif noise_typ == \"saltpepper\":\n",
    "        row, col = image.shape[:2]  # Only use height and width (ignore channels)\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        \n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * row * col * s_vs_p)\n",
    "        coords = [np.random.randint(0, i, int(num_salt)) for i in (row, col)]\n",
    "        out[coords[0], coords[1]] = 1  # Set salt pixels to 1\n",
    "        \n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount * row * col * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i, int(num_pepper)) for i in (row, col)]\n",
    "        out[coords[0], coords[1]] = 0  # Set pepper pixels to 0\n",
    "        \n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ == \"speckle\":\n",
    "        row, col, ch = image.shape\n",
    "        gauss = np.random.randn(row, col, ch)\n",
    "        gauss = gauss.reshape(row, col, ch)\n",
    "        noisy = image + image * gauss\n",
    "        return noisy\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Create a directory to save noisy images\n",
    "output_dir = './mixed_noisy_fashionmnist'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create subdirectories for each class\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "for i, class_name in enumerate(class_names):\n",
    "    os.makedirs(os.path.join(output_dir, class_name), exist_ok=True)\n",
    "\n",
    "# Add noise to the dataset (half Gaussian, half Salt & Pepper)\n",
    "dataset_size = len(trainset)\n",
    "half_size = dataset_size // 2\n",
    "\n",
    "for idx, (image, label) in enumerate(trainloader):\n",
    "    # Convert image to numpy array\n",
    "    img = image.squeeze().numpy()  # Remove batch dimension and convert to numpy\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    \n",
    "    # Apply Gaussian noise to the first half\n",
    "    if idx < half_size:\n",
    "        noisy_img = noisy(\"gauss\", img)\n",
    "    # Apply Salt & Pepper noise to the second half\n",
    "    else:\n",
    "        noisy_img = noisy(\"saltpepper\", img)\n",
    "    \n",
    "    noisy_img = np.squeeze(noisy_img)  # Remove channel dimension\n",
    "    \n",
    "    # Convert back to PIL image\n",
    "    noisy_img = (noisy_img * 255).astype(np.uint8)  # Scale to 0-255\n",
    "    noisy_img = Image.fromarray(noisy_img, mode='L')  # Convert to PIL image\n",
    "    \n",
    "    # Save the noisy image\n",
    "    class_name = class_names[label]\n",
    "    save_path = os.path.join(output_dir, class_name, f'noisy_{idx}.png')\n",
    "    noisy_img.save(save_path)\n",
    "\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"Processed {idx + 1} images\")\n",
    "\n",
    "print(\"Mixed noisy dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
